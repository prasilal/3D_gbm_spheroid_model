{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2321bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from collections import Counter\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import numpy as np\n",
    "import imageio\n",
    "import re\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "from skimage import measure, morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cfc9eb",
   "metadata": {},
   "source": [
    "### Load and Analyze Simulation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d715142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stats_from_jld2(filename):\n",
    "    \"\"\"\n",
    "    Load simulation statistics from a JLD2 (HDF5) file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the .jld2 file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing simulation statistics such as cell counts and volumes.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        step = f[\"step\"][()]\n",
    "        cell_voxels = {\n",
    "            int(k): f[\"cell_voxels\"][k][()]\n",
    "            for k in f[\"cell_voxels\"]\n",
    "        }\n",
    "        cell_states = {\n",
    "            int(k): f[\"cell_states\"][k][()].decode(\"utf-8\")\n",
    "            for k in f[\"cell_states\"]\n",
    "        }\n",
    "\n",
    "    # Compute stats\n",
    "    volumes = [len(voxels) for voxels in cell_voxels.values()]\n",
    "    avg_vol = np.mean(volumes)\n",
    "    max_vol = np.max(volumes)\n",
    "    num_cells = len(volumes)\n",
    "    cum_states = list(cell_states.values())\n",
    "    state_counts = Counter(cum_states)\n",
    "\n",
    "    return {\n",
    "        'step': step,\n",
    "        'num_cells': num_cells,\n",
    "        'avg_volume': avg_vol,\n",
    "        'max_volume': max_vol,\n",
    "        'state_counts': state_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bbe32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Function to load and analyze data ---\n",
    "def analyze_sim_folder(folder_path, max_step=None):\n",
    "    \"\"\"\n",
    "    Analyze all simulation results in a folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing simulation .jld2 files.\n",
    "        max_files (int): Optional limit on the number of files to analyze.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of aggregated statistics dictionaries for each simulation file.\n",
    "    \"\"\"\n",
    "    all_stats = []\n",
    "\n",
    "    for fname in sorted(os.listdir(folder_path)):\n",
    "        if fname.endswith(\".jld2\") and \"step_\" in fname:\n",
    "            try:\n",
    "                step_str = fname.split(\"_\")[-1].replace(\".jld2\", \"\")\n",
    "                step_num = int(step_str)\n",
    "                if max_step is not None and step_num > max_step:\n",
    "                    continue\n",
    "                fpath = os.path.join(folder_path, fname)\n",
    "                stats = load_stats_from_jld2(fpath)\n",
    "                all_stats.append(stats)\n",
    "            except (KeyError, ValueError) as e:\n",
    "                print(f\"Skipping file {fname} due to error: {e}\")\n",
    "\n",
    "    all_stats.sort(key=lambda d: d[\"step\"])\n",
    "\n",
    "    steps = [s[\"step\"] for s in all_stats]\n",
    "    num_cells = [s[\"num_cells\"] for s in all_stats]\n",
    "    avg_volumes = [s[\"avg_volume\"] for s in all_stats]\n",
    "    max_volumes = [s[\"max_volume\"] for s in all_stats]\n",
    "\n",
    "    # Get all unique states across steps\n",
    "    all_states = sorted({state for s in all_stats for state in s[\"state_counts\"].keys()})\n",
    "    state_trends = {state: [] for state in all_states}\n",
    "    for s in all_stats:\n",
    "        for state in all_states:\n",
    "            state_trends[state].append(s[\"state_counts\"].get(state, 0))\n",
    "\n",
    "    return {\n",
    "        \"steps\": steps,\n",
    "        \"num_cells\": num_cells,\n",
    "        \"avg_volumes\": avg_volumes,\n",
    "        \"max_volumes\": max_volumes,\n",
    "        \"state_trends\": state_trends,\n",
    "        \"all_states\": all_states\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0a597",
   "metadata": {},
   "source": [
    "### Plot Simulation Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simulation_stats(stats_list, states_to_include=None, labels=None, max_step=None):\n",
    "    \"\"\"\n",
    "    Plot cell state counts over time for one or multiple simulations.\n",
    "\n",
    "    Args:\n",
    "        stats_list (list): List of simulation stats dictionaries.\n",
    "        states_to_include (list): Optional list of states to include in the plot.\n",
    "        labels (list): Optional labels for the simulations.\n",
    "        max_step (int): Maximum step to show in the plot.\n",
    "    \"\"\"\n",
    "    if not isinstance(stats_list, list):\n",
    "        stats_list = [stats_list]\n",
    "    if labels is None:\n",
    "        labels = [f\"Run {i+1}\" for i in range(len(stats_list))]\n",
    "\n",
    "    def filter_by_max_step(stats):\n",
    "        if max_step is None:\n",
    "            return stats\n",
    "        idxs = [i for i, s in enumerate(stats[\"steps\"]) if s <= max_step]\n",
    "        return {\n",
    "            \"steps\": [stats[\"steps\"][i] for i in idxs],\n",
    "            \"num_cells\": [stats[\"num_cells\"][i] for i in idxs],\n",
    "            \"avg_volumes\": [stats[\"avg_volumes\"][i] for i in idxs],\n",
    "            \"max_volumes\": [stats[\"max_volumes\"][i] for i in idxs],\n",
    "            \"state_trends\": {\n",
    "                state: [stats[\"state_trends\"][state][i] for i in idxs]\n",
    "                for state in stats[\"all_states\"]\n",
    "            },\n",
    "            \"all_states\": stats[\"all_states\"]\n",
    "        }\n",
    "\n",
    "    stats_list = [filter_by_max_step(stats) for stats in stats_list]\n",
    "\n",
    "    # --- Plot 1: Total Cell Count ---\n",
    "    plt.figure()\n",
    "    for stats, label in zip(stats_list, labels):\n",
    "        plt.plot(stats[\"steps\"], stats[\"num_cells\"], label=label)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Number of Cells\")\n",
    "    plt.title(\"Total Cell Count Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- Plot 2: Avg and Max Volume ---\n",
    "    plt.figure()\n",
    "    for stats, label in zip(stats_list, labels):\n",
    "        plt.plot(stats[\"steps\"], stats[\"avg_volumes\"], label=f\"{label} - Avg\")\n",
    "        plt.plot(stats[\"steps\"], stats[\"max_volumes\"], '--', label=f\"{label} - Max\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Volume (voxels)\")\n",
    "    plt.title(\"Cell Volume Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- Plot 3: Cell States ---\n",
    "    plt.figure()\n",
    "    for stats, label in zip(stats_list, labels):\n",
    "        states = stats[\"all_states\"]\n",
    "        trends = stats[\"state_trends\"]\n",
    "        steps = stats[\"steps\"]\n",
    "        states_to_plot = states_to_include if states_to_include else states\n",
    "        for state in states_to_plot:\n",
    "            if state in trends:\n",
    "                plt.plot(steps, trends[state], label=f\"{label}\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Cells in State\")\n",
    "    plt.title(\"Necrotic State Counts Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2ecf5",
   "metadata": {},
   "source": [
    "### Save and Reload Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c9ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_stats(stats, filename):\n",
    "    \"\"\"\n",
    "    Save computed statistics to a pickle file.\n",
    "\n",
    "    Args:\n",
    "        stats (dict): Computed statistics.\n",
    "        filename (str): Output file name for the pickle file.\n",
    "    \"\"\"\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(stats, f)\n",
    "def load_stats(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43708e",
   "metadata": {},
   "source": [
    "### Growth Rate Computation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87000e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_growth_rate_over_time(stats, smooth_window=1):\n",
    "    \"\"\"\n",
    "    Compute the instantaneous growth rate from the area or volume data.\n",
    "\n",
    "    Args:\n",
    "        stats (dict): Statistics dictionary from a simulation.\n",
    "        smooth_window (int): Size of smoothing window for growth rate.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (steps, growth_rates) arrays.\n",
    "    \"\"\"\n",
    "    steps = np.array(stats[\"steps\"])\n",
    "    counts = np.array(stats[\"num_cells\"])\n",
    "    \n",
    "    # Raw growth rate per step\n",
    "    delta_counts = np.diff(counts)\n",
    "    delta_steps = np.diff(steps)\n",
    "    growth_rates = delta_counts / delta_steps\n",
    "    mid_steps = (steps[:-1] + steps[1:]) / 2  # Use midpoint for plotting\n",
    "\n",
    "    # Optional smoothing\n",
    "    if smooth_window > 1:\n",
    "        kernel = np.ones(smooth_window) / smooth_window\n",
    "        growth_rates = np.convolve(growth_rates, kernel, mode=\"valid\")\n",
    "        mid_steps = mid_steps[:len(growth_rates)]\n",
    "\n",
    "    return mid_steps, growth_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1365e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_all_growth_rates(stats_list, labels, smooth_window=3, max_step=None):\n",
    "    \"\"\"\n",
    "    Plot smoothed growth rates for multiple simulations.\n",
    "\n",
    "    Args:\n",
    "        stats_list (list): List of stats dictionaries.\n",
    "        labels (list): Labels for each simulation.\n",
    "        smooth_window (int): Smoothing window size.\n",
    "        max_step (int): Optional maximum step to include.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for stats, label in zip(stats_list, labels):\n",
    "        steps, growth = compute_growth_rate_over_time(stats, smooth_window=smooth_window)\n",
    "\n",
    "        # Filter steps and growth if max_step is given\n",
    "        if max_step is not None:\n",
    "            mask = steps <= max_step\n",
    "            steps = steps[mask]\n",
    "            growth = growth[mask]\n",
    "\n",
    "        plt.plot(steps, growth, label=label)\n",
    "\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Growth Rate (Δcells / step)\")\n",
    "    plt.title(\"Instantaneous Cell Growth Rate Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d7a8d",
   "metadata": {},
   "source": [
    "### Extract and Plot Area Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d805cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "def extract_area_metrics(\n",
    "    input_folder,\n",
    "    output_file,\n",
    "    voxel_size_um=2.0,\n",
    "    projection_axis='z'\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract spheroid area metrics from image files and save as CSV.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Folder containing image data.\n",
    "        output_file (str): Path to output CSV.\n",
    "        voxel_size (float): Conversion factor for voxel to microns.\n",
    "        step_interval (int): Time between steps in hours.\n",
    "    \"\"\"\n",
    "    def load_cell_voxels_from_jld2(file_path):\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            cell_voxels = {}\n",
    "            max_coord = np.array([0, 0, 0])\n",
    "            for cell_id in f[\"cell_voxels\"]:\n",
    "                raw = f[\"cell_voxels\"][cell_id][()]\n",
    "                if raw.dtype.names:\n",
    "                    voxels = np.stack([raw[name] for name in raw.dtype.names], axis=-1)\n",
    "                else:\n",
    "                    voxels = raw\n",
    "                if voxels.size > 0:\n",
    "                    max_coord = np.maximum(max_coord, voxels.max(axis=0))\n",
    "                cell_voxels[int(cell_id)] = voxels\n",
    "            grid_shape = tuple(max_coord + 1)\n",
    "        return cell_voxels, grid_shape\n",
    "\n",
    "    def project_voxels_to_2D(cell_voxels, grid_shape):\n",
    "        axis_map = {'x': (1, 2), 'y': (0, 2), 'z': (0, 1)}\n",
    "        ax1, ax2 = axis_map[projection_axis]\n",
    "        mask = np.zeros((grid_shape[ax1], grid_shape[ax2]), dtype=np.uint8)\n",
    "        all_voxels = np.concatenate(list(cell_voxels.values()))\n",
    "        for voxel in all_voxels:\n",
    "            i, j = voxel[ax1], voxel[ax2]\n",
    "            if 0 <= i < mask.shape[0] and 0 <= j < mask.shape[1]:\n",
    "                mask[i, j] = 1\n",
    "        return mask\n",
    "\n",
    "    def compute_area_metrics(mask):\n",
    "        labeled = morphology.label(mask)\n",
    "        regions = measure.regionprops(labeled)\n",
    "        if not regions:\n",
    "            return 0, 0, 0\n",
    "        region = max(regions, key=lambda r: r.area)\n",
    "        area_px = region.area\n",
    "        perimeter_px = region.perimeter\n",
    "        area_um2 = area_px * voxel_size_um**2\n",
    "        perimeter_um = perimeter_px * voxel_size_um\n",
    "        circularity = (4 * np.pi * area_um2) / (perimeter_um**2) if perimeter_um > 0 else 0\n",
    "        return area_um2, perimeter_um, circularity\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    records = []\n",
    "    for fname in sorted(os.listdir(input_folder)):\n",
    "        if not (fname.endswith(\".jld2\") and \"step_\" in fname):\n",
    "            continue\n",
    "        step_num = int(fname.split(\"_\")[-1].replace(\".jld2\", \"\"))\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        try:\n",
    "            cell_voxels, grid_shape = load_cell_voxels_from_jld2(file_path)\n",
    "            mask = project_voxels_to_2D(cell_voxels, grid_shape)\n",
    "            area, perimeter, circ = compute_area_metrics(mask)\n",
    "            records.append({\n",
    "                \"step\": step_num,\n",
    "                \"area_um2\": area,\n",
    "                \"perimeter_um\": perimeter,\n",
    "                \"circularity\": circ\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    if records:\n",
    "        df = pd.DataFrame(records)\n",
    "        df.sort_values(\"step\", inplace=True)\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved area metrics to: {output_file}\")\n",
    "    else:\n",
    "        print(\"No valid JLD2 files found or all failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68258831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_all_metrics_from_folder(folder=\"area_results\", max_step=None):\n",
    "    \"\"\"\n",
    "    Plot area over time for all CSV files in a folder.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Folder containing area CSV files.\n",
    "        max_step (int): Optional step cutoff for plotting.\n",
    "    \"\"\"\n",
    "\n",
    "    label_map = {\n",
    "        \"10_1\": \"10:1\",\n",
    "        \"3_1\": \"3:1\",\n",
    "        \"1_1\": \"1:1\",\n",
    "        \"1_3\": \"1:3\",\n",
    "        \"2_1\": \"2:1\",\n",
    "        \"5_1\": \"5:1\",\n",
    "        \"20_1\": \"20:1\",\n",
    "        \"GBM\": \"GBM\",\n",
    "        \"MSC\": \"MSC\"\n",
    "    }\n",
    "\n",
    "    files = sorted([f for f in os.listdir(folder) if f.endswith(\"_metrics.csv\")])\n",
    "    if not files:\n",
    "        print(\"No CSV files found.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # --- Subplot 1: Area ---\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for fname in files:\n",
    "        df = pd.read_csv(os.path.join(folder, fname))\n",
    "        if max_step is not None:\n",
    "            df = df[df[\"step\"] <= max_step]\n",
    "        prefix = fname.split(\"_\")[0]\n",
    "        label = label_map.get(prefix, prefix)\n",
    "        plt.plot(df[\"step\"], df[\"area_um2\"], label=label)\n",
    "    plt.title(\"Projected Area (µm²)\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Area\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # --- Subplot 2: Perimeter ---\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for fname in files:\n",
    "        df = pd.read_csv(os.path.join(folder, fname))\n",
    "        if max_step is not None:\n",
    "            df = df[df[\"step\"] <= max_step]\n",
    "        prefix = fname.split(\"_\")[0]\n",
    "        label = label_map.get(prefix, prefix)\n",
    "        plt.plot(df[\"step\"], df[\"perimeter_um\"], label=label)\n",
    "    plt.title(\"Perimeter (µm)\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Perimeter\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # --- Subplot 3: Circularity ---\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for fname in files:\n",
    "        df = pd.read_csv(os.path.join(folder, fname))\n",
    "        if max_step is not None:\n",
    "            df = df[df[\"step\"] <= max_step]\n",
    "        prefix = fname.split(\"_\")[0]\n",
    "        label = label_map.get(prefix, prefix)\n",
    "        plt.plot(df[\"step\"], df[\"circularity\"], label=label)\n",
    "    plt.title(\"Circularity\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Circularity\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.suptitle(\"Spheroid Shape Metrics Over Time\", fontsize=14, y=1.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179ddf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_normalized_area_from_folder(folder=\"area_results\", target_start_area=1000.0, max_step=None):\n",
    "    \"\"\"\n",
    "    Plot normalized spheroid area over time from CSV files in a folder.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Folder with area CSVs.\n",
    "        target_start_area (float): Area to normalize the start to (e.g., 1.0).\n",
    "    \"\"\"\n",
    "\n",
    "    label_map = {\n",
    "        \"10_1\": \"10:1\",\n",
    "        \"3_1\": \"3:1\",\n",
    "        \"1_1\": \"1:1\",\n",
    "        \"1_3\": \"1:3\",\n",
    "        \"2_1\": \"2:1\",\n",
    "        \"5_1\": \"5:1\",\n",
    "        \"20_1\": \"20:1\",\n",
    "        \"GBM\": \"GBM\",\n",
    "        \"MSC\": \"MSC\"\n",
    "    }\n",
    "\n",
    "    files = sorted([f for f in os.listdir(folder) if f.endswith(\"_metrics.csv\")])\n",
    "    if not files:\n",
    "        print(\"No CSV files found.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for fname in files:\n",
    "        df = pd.read_csv(os.path.join(folder, fname))\n",
    "\n",
    "        if df.empty or df[\"area_um2\"].iloc[0] == 0:\n",
    "            print(f\"Warning: {fname} skipped due to missing or invalid start area.\")\n",
    "            continue\n",
    "\n",
    "        if max_step is not None:\n",
    "            df = df[df[\"step\"] <= max_step]\n",
    "            if df.empty:\n",
    "                print(f\"Warning: no data within max_step for {fname}\")\n",
    "                continue\n",
    "\n",
    "        prefix = fname.split(\"_\")[0]\n",
    "        label = label_map.get(prefix, prefix)\n",
    "\n",
    "        steps = df[\"step\"].values\n",
    "        areas = df[\"area_um2\"].values\n",
    "        normalized_areas = (areas / areas[0]) * target_start_area\n",
    "\n",
    "        plt.plot(steps, normalized_areas, label=label)\n",
    "\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Normalized Area (µm²)\")\n",
    "    plt.title(f\"Normalized Spheroid Area Growth (Start = {target_start_area:.0f} µm²)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_cut_view_gif(slice_x, batch, condition):\n",
    "    \"\"\"\n",
    "    Creates an animated GIF showing the evolution of a 2D slice (in the x-plane) \n",
    "    through a 3D spheroid simulation across time.\n",
    "\n",
    "    Parameters:\n",
    "    - slice_x (int): The x-coordinate at which to slice the 3D grid.\n",
    "    - batch (str): Name of the batch (used to locate the simulation output).\n",
    "    - condition (str): Simulation condition (e.g., \"gbm_msc_25\") used as folder name.\n",
    "\n",
    "    Workflow:\n",
    "    - Loads `.jld2` step files from the corresponding simulation output directory.\n",
    "    - Extracts voxel positions and cell states at the specified slice.\n",
    "    - Assigns each cell state a unique color and renders the slice at each timepoint.\n",
    "    - Assembles the resulting PNGs into a GIF stored in `cut_views/`.\n",
    "\n",
    "    Output:\n",
    "    - Saves the frame images in `slice_frames/`.\n",
    "    - Saves the animated GIF in `cut_views/cut_view_{batch}_{condition}.gif`.\n",
    "\n",
    "    Requirements:\n",
    "    - Assumes the input files are structured in `sim_output/{batch}/{condition}/sim_output/`\n",
    "      and follow the `step_XXX.jld2` naming convention.\n",
    "    \"\"\"\n",
    "    # --- Settings ---\n",
    "    print(f\"Creating cut view GIF for batch {batch}, condition {condition} at slice x={slice_x}\")\n",
    "    GRID_SIZE = (70, 70, 70)\n",
    "    input_dir = f\"sim_output/{batch}/{condition}/sim_output\"\n",
    "    output_dir = \"slice_frames\"\n",
    "    gif_output_path = f\"cut_views/cut_view_{batch}_{condition}.gif\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(gif_output_path), exist_ok=True)\n",
    "\n",
    "    # --- Automatically get all available steps ---\n",
    "    step_files = sorted([\n",
    "        f for f in os.listdir(input_dir)\n",
    "        if re.match(r\"step_\\d+\\.jld2\", f)\n",
    "    ])\n",
    "    step_numbers = [int(re.findall(r\"\\d+\", f)[0]) for f in step_files]\n",
    "\n",
    "    # --- Build color map for cell states ---\n",
    "    unique_states = set()\n",
    "    for fname in step_files:\n",
    "        with h5py.File(os.path.join(input_dir, fname), \"r\") as f:\n",
    "            for k in f[\"cell_states\"]:\n",
    "                unique_states.add(f[\"cell_states\"][k][()].decode(\"utf-8\"))\n",
    "\n",
    "    unique_states = sorted(unique_states)\n",
    "    state_to_idx = {s: i + 1 for i, s in enumerate(unique_states)}  # background = 0\n",
    "\n",
    "    # Create a custom colormap with black background\n",
    "    base_cmap = plt.get_cmap(\"tab10\")\n",
    "    colors = [(0, 0, 0)] + [base_cmap(i / len(unique_states))[:3] for i in range(len(unique_states))]\n",
    "    custom_cmap = ListedColormap(colors)\n",
    "\n",
    "    # --- Generate slice images ---\n",
    "    frame_paths = []\n",
    "\n",
    "    for step, fname in zip(step_numbers, step_files):\n",
    "        with h5py.File(os.path.join(input_dir, fname), \"r\") as f:\n",
    "            cell_voxels = {\n",
    "                int(k): np.array([list(t) for t in f[\"cell_voxels\"][k][()]]).astype(int)\n",
    "                for k in f[\"cell_voxels\"]\n",
    "            }\n",
    "            cell_states = {\n",
    "                int(k): f[\"cell_states\"][k][()].decode(\"utf-8\")\n",
    "                for k in f[\"cell_states\"]\n",
    "            }\n",
    "\n",
    "        slice_image = np.zeros((GRID_SIZE[1], GRID_SIZE[2]), dtype=int)  # Background = 0\n",
    "\n",
    "        for cid, voxels in cell_voxels.items():\n",
    "            state = cell_states[cid]\n",
    "            color_idx = state_to_idx[state]\n",
    "            for x, y, z in voxels:\n",
    "                if x == slice_x:\n",
    "                    slice_image[y, z] = color_idx\n",
    "\n",
    "        # Plot the slice\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        im = plt.imshow(slice_image.T, origin='lower', cmap=custom_cmap, vmin=0, vmax=len(unique_states))\n",
    "        plt.title(f\"Step {step} at x={slice_x}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Create colorbar skipping background\n",
    "        cbar = plt.colorbar(im, ticks=range(1, len(unique_states)+1))\n",
    "        cbar.ax.set_yticklabels(unique_states)\n",
    "\n",
    "        frame_path = os.path.join(output_dir, f\"slice_{step:05d}.png\")\n",
    "        plt.savefig(frame_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        frame_paths.append(frame_path)\n",
    "\n",
    "    # --- Create GIF ---\n",
    "    images = [imageio.imread(f) for f in frame_paths]\n",
    "    imageio.mimsave(gif_output_path, images, fps=2)\n",
    "\n",
    "    print(f\"✅ Done! GIF saved at: {gif_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120693e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_volume_metrics(input_folder, output_csv, voxel_volume_um3=8.0):\n",
    "    \"\"\"\n",
    "    Extracts 3D volume (μm³) from .jld2 simulation files in the given folder.\n",
    "\n",
    "    Parameters:\n",
    "    - input_folder (str): path to folder with .jld2 files\n",
    "    - output_csv (str): path to output .csv file\n",
    "    - voxel_volume_um3 (float): volume of one voxel (default 2x2x2 μm = 8.0)\n",
    "    \"\"\"\n",
    "\n",
    "    def load_cell_voxels_from_jld2(file_path):\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            cell_voxels = {\n",
    "                int(k): f[\"cell_voxels\"][k][()]\n",
    "                for k in f[\"cell_voxels\"]\n",
    "            }\n",
    "        return cell_voxels\n",
    "\n",
    "    def compute_volume(cell_voxels):\n",
    "        return sum(len(voxels) for voxels in cell_voxels.values()) * voxel_volume_um3\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "    records = []\n",
    "\n",
    "    for fname in sorted(os.listdir(input_folder)):\n",
    "        if not (fname.endswith(\".jld2\") and \"step_\" in fname):\n",
    "            continue\n",
    "        step_num = int(fname.split(\"_\")[-1].replace(\".jld2\", \"\"))\n",
    "        file_path = os.path.join(input_folder, fname)\n",
    "\n",
    "        try:\n",
    "            cell_voxels = load_cell_voxels_from_jld2(file_path)\n",
    "            volume_um3 = compute_volume(cell_voxels)\n",
    "            records.append({\"step\": step_num, \"volume_um3\": volume_um3})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    if records:\n",
    "        df = pd.DataFrame(records)\n",
    "        df.sort_values(\"step\", inplace=True)\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"Saved volume metrics to: {output_csv}\")\n",
    "    else:\n",
    "        print(\"No valid volume data extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8224b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_condition(condition, folder):\n",
    "    save_stats(analyze_sim_folder(f\"sim_output/{folder}/{condition}/sim_output\", max_step=130),\n",
    "               f\"saved_stats/{folder}/stats_{condition}.pkl\")\n",
    "    print(f\"Saved stats for {condition} for batch {folder}\")\n",
    "    extract_volume_metrics(\n",
    "        input_folder=f\"sim_output/{folder}/{condition}/sim_output\",\n",
    "        output_csv=f\"volume_results/{folder}/{condition}_volume.csv\"\n",
    "    )\n",
    "    make_cut_view_gif(slice_x=35, batch=folder, condition=condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3e696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder, ratios = [\"10_1\", \"3_1\", \"1_1\", \"1_3\", \"2_1\", \"5_1\", \"20_1\", \"GBM\", \"MSC\"]):\n",
    "    for ratio in ratios:\n",
    "        process_condition(ratio, folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
